#!/bin/bash
# Quick verification script for batch inference integration

echo "======================================================================"
echo "BATCH INFERENCE INTEGRATION VERIFICATION"
echo "======================================================================"
echo ""
echo "This script will help you verify the batch inference integration."
echo "You'll need to run the server manually in another terminal."
echo ""
echo "======================================================================"
echo "STEP 1: Start BloomBee Server"
echo "======================================================================"
echo ""
echo "In another terminal, run:"
echo ""
echo "  cd /Users/dannyliu/Documents/bloom_batching/BloomBee_integrated"
echo "  python -m bloombee.cli.run_server huggyllama/llama-7b \\"
echo "    --num_blocks 16 --device cpu --torch_dtype float32 \\"
echo "    --skip_reachability_check --new_swarm --no_auto_relay \\"
echo "    --host_maddrs /ip4/127.0.0.1/tcp/29501"
echo ""
echo "Wait for server to show 'Started' message, then note the peer ID."
echo ""
echo "======================================================================"
echo "STEP 2: Run Batch Scaling Test"
echo "======================================================================"
echo ""
echo "Once server is ready, run:"
echo ""
echo "  python benchmarks/simple_batch_scaling.py /ip4/127.0.0.1/tcp/29501/p2p/<PEER_ID>"
echo ""
echo "Expected output:"
echo "  - Batch 1-64 should complete successfully"
echo "  - Should show increasing tokens/sec with batch size"
echo "  - Should display speedup and efficiency metrics"
echo ""
echo "======================================================================"
echo "STEP 3: Test TinyLlama (Optional)"
echo "======================================================================"
echo ""
echo "For TinyLlama verification:"
echo ""
echo "  1. Start TinyLlama server:"
echo "     python -m bloombee.cli.run_server TinyLlama/TinyLlama-1.1B-Chat-v1.0 \\"
echo "       --num_blocks 22 --device cpu --torch_dtype float32"
echo ""
echo "  2. Run benchmark:"
echo "     python benchmarks/simple_batch_scaling.py /ip4/.../p2p/<PEER_ID> TinyLlama/TinyLlama-1.1B-Chat-v1.0"
echo ""
echo "======================================================================"
echo "VERIFICATION CHECKLIST"
echo "======================================================================"
echo ""
echo "☐ Batch scaling test completes successfully"
echo "☐ Performance metrics match expectations (see INTEGRATION_COMPLETE_README.txt)"
echo "☐ No errors or crashes during testing"
echo "☐ TinyLlama loads and inferences correctly (if testing)"
echo ""
echo "If all checks pass, integration is successful and ready for PR!"
echo ""
echo "======================================================================"





